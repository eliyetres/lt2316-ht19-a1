import argparse
import os
import sys
import argparse
import time
import pickle
import torch
from sklearn.metrics import classification_report
from get_data import load_data

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

X_test,y_test = load_data("x_test.txt", "y_test.txt")

loaded_model = joblib.load(filename) # load the model from disk

result = loaded_model.score(X_test, Y_test)
print(result)


def predict(model,  x_test, y_test):
    dev = torch.device("cuda:0")
    indices = [bl.vocabindex[word] for word in prefix.split()]
    indices = torch.LongTensor(np.array([indices])).to(dev)
    # We need to add a trivial sentence length parameter to the model.
    result = model((indices, torch.LongTensor([1]).to(dev)))
    return result


predictions = predict(trained_batch, sentence)
predictions[0][-1].topk(1)[1].item()

# parser = argparse.ArgumentParser(description="Tests the model.")

# parser.add_argument("-m", "--model_name", metavar="m", dest="model_name", type=str, help="The previously saved network model.")

# args = parser.parse_args()


# Write a testing script that takes the model generated by the training script and testing instances and class labels as arguments, 
# analogous to the training script.  
# Document the command line arguments, including any you needed to add.  
# The testing script should do the following:

# for each testing instance, print whether at any character prefix length, the most probable class was the correct one.
# the overall accuracy in terms of how often the correct class was ever the most probable at any character prefix length.
# the number of characters until hit score for all those instances where the highest probability was ever the correct class.
# the mean average number of characters until hit score.
# the number of instances for which the correct class was never the highest.

# print("Loading model from {}.".format(args.model_name))
# pre_trained_model = load_gensim_model(args.model_name)



# # Validation
#     with torch.set_grad_enabled(False):
#         for local_batch, local_labels in validation_generator:
#             # Transfer to GPU
#             local_batch, local_labels = local_batch.to(device), local_labels.to(device)

#             # Model computations
#             [...]